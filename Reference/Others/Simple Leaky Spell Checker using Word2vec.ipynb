{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "01959eac-42a4-9445-9d7f-06325684f193",
        "_uuid": "9f770ec49e783a584e1f64fea959b1df1c8ec035"
      },
      "cell_type": "markdown",
      "source": "I have been struggling for a while on how to spell check questions while only using allowed data/software.  Here is the solution I am using now.\n\nIt is an adaptation of Peter Norvig's spell checker.  It uses word2vec ordering of words to approximate word probabilities.  Indeed, Google word2vec apparently orders words in decreasing order of frequency in the training corpus.\n\nThis kernel requires to download Google's word2vec: https://github.com/mmihaltz/word2vec-GoogleNews-vectors .  I have put it in my ../data directory.\n\nI don't think that  the notebooks can run on Kaggle kernels but I share it anyway as many have already downloaded the word2vec embedding."
    },
    {
      "metadata": {
        "_cell_guid": "1d7bd7dc-bae7-4313-856b-bdc10e447644",
        "_uuid": "4ccb152117d943ed360c5c7fa7e9bc87428cce55",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "36d0c3a7-e625-44d9-6f71-ae8df520a1cb",
        "_uuid": "5c8cb9bd31594684c49f00a5453126f8c2341681",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import gensim\nmodel = gensim.models.KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin.gz', \n                                                        binary=True)\n\nwords = model.index2word\n\nw_rank = {}\nfor i,word in enumerate(words):\n    w_rank[word] = i\n\nWORDS = w_rank",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e9756896-0a0a-81d0-66d9-821f7cdc8281",
        "_uuid": "698cbda26eb5f41c6361f456680eaf7fcdf2a4da"
      },
      "cell_type": "markdown",
      "source": "The rest of the code is a simple modification of Peter Norvig's code. Instead of computing the frequency of each word we use the above rank."
    },
    {
      "metadata": {
        "_cell_guid": "c1a89822-cb6e-393d-ffaa-af0604ea68dc",
        "_uuid": "826983212cdb9ea2ebc27d6a367eeac655e4750c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import re\nfrom collections import Counter\n\ndef words(text): return re.findall(r'\\w+', text.lower())\n\ndef P(word): \n    \"Probability of `word`.\"\n    # use inverse of rank as proxy\n    # returns 0 if the word isn't in the dictionary\n    return - WORDS.get(word, 0)\n\ndef correction(word): \n    \"Most probable spelling correction for word.\"\n    return max(candidates(word), key=P)\n\ndef candidates(word): \n    \"Generate possible spelling corrections for word.\"\n    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n\ndef known(words): \n    \"The subset of `words` that appear in the dictionary of WORDS.\"\n    return set(w for w in words if w in WORDS)\n\ndef edits1(word):\n    \"All edits that are one edit away from `word`.\"\n    letters    = 'abcdefghijklmnopqrstuvwxyz'\n    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n    deletes    = [L + R[1:]               for L, R in splits if R]\n    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n    inserts    = [L + c + R               for L, R in splits for c in letters]\n    return set(deletes + transposes + replaces + inserts)\n\ndef edits2(word): \n    \"All edits that are two edits away from `word`.\"\n    return (e2 for e1 in edits1(word) for e2 in edits1(e1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "26e763f3-e3fc-1415-0453-31cb390ab4a9",
        "_uuid": "7858c94b88a4d859403f34b54d3cd112e3ed35be"
      },
      "cell_type": "markdown",
      "source": "That's it. If you have downloaded word2vec then you can start using this code.  Here are few examples of what it does.\n\ncorrection('quikly') returns quickly\n\ncorrection('israil') returns israel\n\ncorrection('neighbour') returns neighbor"
    },
    {
      "metadata": {
        "_cell_guid": "8160d9e9-4e82-53dc-bed1-d537885571e4",
        "_uuid": "120d550106739a98164e8da76398328bc0878540"
      },
      "cell_type": "markdown",
      "source": "If you like this notebook then please upvote (button at the top right)."
    },
    {
      "metadata": {
        "_cell_guid": "d2c822e9-8aea-9b4d-1e87-538cb8dab4f2",
        "_uuid": "3bd2a6a59ce19affd9927ff95bf6bbb2f0c4aba6",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}